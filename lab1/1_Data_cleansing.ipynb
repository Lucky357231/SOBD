{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа № 1 \n",
    "## Выполнение разведочного анализа больших данных с использованием фреймворка Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 1\n",
    "\n",
    "В данной части работы рассмотрены:\n",
    "* загрузка данных из HDFS;\n",
    "* базовые преобразования данных;\n",
    "* загрузка преобразованных данных в таблицу `Apache Airflow`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключим необходимые библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import (\n",
    "    regexp_replace,\n",
    "    regexp_extract_all,\n",
    "    col,\n",
    "    lit\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем объект конфигурации для `Apache Spark`, указав необходимые параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_configuration() -> SparkConf:\n",
    "    \"\"\"\n",
    "    Создает и конфигурирует экземпляр SparkConf для приложения Spark.\n",
    "\n",
    "    Returns:\n",
    "        SparkConf: Настроенный экземпляр SparkConf.\n",
    "    \"\"\"\n",
    "    # Получаем имя пользователя\n",
    "    user_name = os.getenv(\"USER\")\n",
    "    \n",
    "    conf = SparkConf()\n",
    "    conf.setAppName(\"lab 1 Test\")\n",
    "    conf.setMaster(\"yarn\")\n",
    "    conf.set(\"spark.submit.deployMode\", \"client\")\n",
    "    conf.set(\"spark.executor.memory\", \"12g\")\n",
    "    conf.set(\"spark.executor.cores\", \"8\")\n",
    "    conf.set(\"spark.executor.instances\", \"2\")\n",
    "    conf.set(\"spark.driver.memory\", \"4g\")\n",
    "    conf.set(\"spark.driver.cores\", \"2\")\n",
    "    conf.set(\"spark.jars.packages\", \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.0\")\n",
    "    conf.set(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "    conf.set(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    conf.set(\"spark.sql.catalog.spark_catalog.type\", \"hadoop\")\n",
    "    conf.set(\"spark.sql.catalog.spark_catalog.warehouse\", f\"hdfs:///user/{user_name}/warehouse\")\n",
    "    conf.set(\"spark.sql.catalog.spark_catalog.io-impl\", \"org.apache.iceberg.hadoop.HadoopFileIO\")\n",
    "\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём сам объект конфигурации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = create_spark_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём и выводим на экран сессию `Apache Spark`. В процессе создания сессии происходит подключение к кластеру `Apache Hadoop`, что может занять некоторое время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/07 02:17:39 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "24/12/07 02:17:57 WARN Client: Same path resource file:///home/user6/.ivy2/jars/org.apache.iceberg_iceberg-spark-runtime-3.5_2.12-1.6.0.jar added multiple times to distributed cache.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://node32.cluster:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>lab 1 Test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f2592d5e350>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для исследования будем использовать датасет `\"US Used cars dataset\"`, расположенный на платформе `Kaggle` по адресу https://www.kaggle.com/datasets/ananaymital/us-used-cars-dataset.\n",
    "\n",
    "Датасет включает в себя информацию о более чем трех миллионах используемых машин в США. Он разрешен для использования в учебных целях.\n",
    "\n",
    "Данный датасет уже загружен в `HDFS` по адресу: `hdfs:///datasets/used_cars_data.csv`\n",
    "\n",
    "Указываем путь в `HDFS` для файла с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"hdfs:///datasets/HI-Medium_Trans.csv\"\n",
    "path = \"hdfs:///user/user6/khripunov_directory/HI-Medium_Trans.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполняем датафрейм данными из файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/07 02:18:47 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = (spark.read.format(\"csv\")\n",
    "      .option(\"header\", \"true\")\n",
    "      .load(path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводим фрагмент датафрейма на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
      "|       Timestamp|From Bank| Account2|To Bank| Account4|Amount Received|Receiving Currency|Amount Paid|Payment Currency|Payment Format|Is Laundering|\n",
      "+----------------+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
      "|2022/09/01 00:17|      020|800104D70|    020|800104D70|        6794.63|         US Dollar|    6794.63|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:02|    03196|800107150|  03196|800107150|        7739.29|         US Dollar|    7739.29|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:17|    01208|80010E430|  01208|80010E430|        1880.23|         US Dollar|    1880.23|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:03|    01208|80010E650|    020|80010E6F0|    73966883.00|         US Dollar|73966883.00|       US Dollar|        Cheque|            0|\n",
      "|2022/09/01 00:02|    01208|80010E650|    020|80010EA30|    45868454.00|         US Dollar|45868454.00|       US Dollar|        Cheque|            0|\n",
      "|2022/09/01 00:27|    03203|80010EA80|  03203|80010EA80|       13284.41|         US Dollar|   13284.41|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:25|      020|800104D20|    020|800104D20|           9.72|         US Dollar|       9.72|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:09|    01208|80010E430|  01208|80010E430|           7.66|         US Dollar|       7.66|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:09|      011|80010E600|    011|80010E600|          16.33|         US Dollar|      16.33|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:06|    01208|80010E650|  01208|80010E650|           4.86|         US Dollar|       4.86|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:25|      020|80010E6F0|0183112|84DCA3150|           3.24|         US Dollar|       3.24|       US Dollar|   Credit Card|            0|\n",
      "|2022/09/01 00:16|      020|80010EA30|  01601|802B6D220|          47.17|         US Dollar|      47.17|       US Dollar|   Credit Card|            0|\n",
      "|2022/09/01 00:14|      020|800073020|    020|800073020|      848368.76|         US Dollar|  848368.76|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:05|    03566|800345920|  03566|800345920|       10134.05|         US Dollar|   10134.05|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:09|      011|800329930|  02776|800816450|      335999.68|         US Dollar|  335999.68|       US Dollar|        Cheque|            0|\n",
      "|2022/09/01 00:07|      000|8009B22F0|    000|8009B22F0|         121.98|         US Dollar|     121.98|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:24|      011|8003289F0|0249457|825F4B630|          45.39|         US Dollar|      45.39|       US Dollar|   Credit Card|            0|\n",
      "|2022/09/01 00:22|      000|800815DE0|    000|800815DE0|          23.40|         US Dollar|      23.40|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:28|    02776|800816450|0071901|81AB268F0|          30.23|         US Dollar|      30.23|       US Dollar|   Credit Card|            0|\n",
      "|2022/09/01 00:21|   011081|8008DDDF0| 011081|8008DDDF0|           7.37|         US Dollar|       7.37|       US Dollar|  Reinvestment|            0|\n",
      "+----------------+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, что в целях сохранения ясности изложения и сокращения расчетного времени имеет смысл рассматривать не все солбцы датасета. Оставим следующие колонки, удалив остальные:\n",
    "\n",
    "| Название столбца  | Расшифровка |\n",
    "| ------------- | ------------- |\n",
    "| Timestamp         | Дата и время выполнения транзакции  |\n",
    "| From Bank\t        | Банк, откуда была отправлена транзакция  |\n",
    "| To Bank           | Банк, куда была отправлена транзакция |\n",
    "| Amount Received   | Полученная сумма\n",
    "| Amount Paid       | Сумма, отправленная отправителем |\n",
    "| Payment Currency  | Валюта отправленной суммы |\n",
    "| Payment Format\t| Формат платежа (например, \"Reinvestment\", \"Cheque\")  |\n",
    "| Is Laundering\t    | Флаг, указывающий, является ли транзакция подозрительной (0 или 1) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(\n",
    "    \"Timestamp\", \"From Bank\", \"To Bank\", \"Amount Received\", \"Amount Paid\", \"Payment Currency\", \"Payment Format\",\n",
    "    \"Is Laundering\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+-------+---------------+-----------+----------------+--------------+-------------+\n",
      "|       Timestamp|From Bank|To Bank|Amount Received|Amount Paid|Payment Currency|Payment Format|Is Laundering|\n",
      "+----------------+---------+-------+---------------+-----------+----------------+--------------+-------------+\n",
      "|2022/09/01 00:17|      020|    020|        6794.63|    6794.63|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:02|    03196|  03196|        7739.29|    7739.29|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:17|    01208|  01208|        1880.23|    1880.23|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:03|    01208|    020|    73966883.00|73966883.00|       US Dollar|        Cheque|            0|\n",
      "|2022/09/01 00:02|    01208|    020|    45868454.00|45868454.00|       US Dollar|        Cheque|            0|\n",
      "|2022/09/01 00:27|    03203|  03203|       13284.41|   13284.41|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:25|      020|    020|           9.72|       9.72|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:09|    01208|  01208|           7.66|       7.66|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:09|      011|    011|          16.33|      16.33|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:06|    01208|  01208|           4.86|       4.86|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:25|      020|0183112|           3.24|       3.24|       US Dollar|   Credit Card|            0|\n",
      "|2022/09/01 00:16|      020|  01601|          47.17|      47.17|       US Dollar|   Credit Card|            0|\n",
      "|2022/09/01 00:14|      020|    020|      848368.76|  848368.76|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:05|    03566|  03566|       10134.05|   10134.05|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:09|      011|  02776|      335999.68|  335999.68|       US Dollar|        Cheque|            0|\n",
      "|2022/09/01 00:07|      000|    000|         121.98|     121.98|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:24|      011|0249457|          45.39|      45.39|       US Dollar|   Credit Card|            0|\n",
      "|2022/09/01 00:22|      000|    000|          23.40|      23.40|       US Dollar|  Reinvestment|            0|\n",
      "|2022/09/01 00:28|    02776|0071901|          30.23|      30.23|       US Dollar|   Credit Card|            0|\n",
      "|2022/09/01 00:21|   011081| 011081|           7.37|       7.37|       US Dollar|  Reinvestment|            0|\n",
      "+----------------+---------+-------+---------------+-----------+----------------+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем на экран метаданные датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Timestamp: string (nullable = true)\n",
      " |-- From Bank: string (nullable = true)\n",
      " |-- To Bank: string (nullable = true)\n",
      " |-- Amount Received: string (nullable = true)\n",
      " |-- Amount Paid: string (nullable = true)\n",
      " |-- Payment Currency: string (nullable = true)\n",
      " |-- Payment Format: string (nullable = true)\n",
      " |-- Is Laundering: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что все столбцы датасета содержат строковый тип данных, что не соответствует ожиданиям. Выполним преобразования типов данных некоторых столбцов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31863008"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_dataframe(data: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Преобразует столбцы DataFrame в указанные типы данных и\n",
    "    выполняет необходимые преобразования.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): Исходный DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Преобразованный DataFrame.\n",
    "    \"\"\"\n",
    "    # Преобразуем столбцы в соответствующие типы данных\n",
    "    data = data.withColumn(\"Timestamp\", col(\"Timestamp\").cast(\"Timestamp\"))  # Дата и время\n",
    "    data = data.withColumn(\"Amount Received\", col(\"Amount Received\").cast(\"Float\"))  # Полученная сумма\n",
    "    data = data.withColumn(\"Amount Paid\", col(\"Amount Paid\").cast(\"Float\"))  # Сумма отправления\n",
    "    data = data.withColumn(\"Is Laundering\", col(\"Is Laundering\").cast(\"Boolean\"))  # Флаг подозрительности\n",
    "    \n",
    "    # Убираем валютные обозначения в столбцах валют (при необходимости)\n",
    "    data = data.withColumn(\"Payment Currency\", regexp_replace(col(\"Payment Currency\"), r\"\\s+Dollar\", \"\").alias(\"Payment Currency\"))\n",
    "\n",
    "    return data\n",
    "\n",
    "# Подсчёт записей с Is Laundering == True\n",
    "df.filter(col(\"Is Laundering\") == False).count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = transform_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------+---------------+-----------+----------------+--------------+-------------+\n",
      "|Timestamp|From Bank|To Bank|Amount Received|Amount Paid|Payment Currency|Payment Format|Is Laundering|\n",
      "+---------+---------+-------+---------------+-----------+----------------+--------------+-------------+\n",
      "|     NULL|      020|    020|        6794.63|    6794.63|              US|  Reinvestment|        false|\n",
      "|     NULL|    03196|  03196|        7739.29|    7739.29|              US|  Reinvestment|        false|\n",
      "|     NULL|    01208|  01208|        1880.23|    1880.23|              US|  Reinvestment|        false|\n",
      "|     NULL|    01208|    020|     7.396688E7| 7.396688E7|              US|        Cheque|        false|\n",
      "|     NULL|    01208|    020|    4.5868456E7|4.5868456E7|              US|        Cheque|        false|\n",
      "|     NULL|    03203|  03203|       13284.41|   13284.41|              US|  Reinvestment|        false|\n",
      "|     NULL|      020|    020|           9.72|       9.72|              US|  Reinvestment|        false|\n",
      "|     NULL|    01208|  01208|           7.66|       7.66|              US|  Reinvestment|        false|\n",
      "|     NULL|      011|    011|          16.33|      16.33|              US|  Reinvestment|        false|\n",
      "|     NULL|    01208|  01208|           4.86|       4.86|              US|  Reinvestment|        false|\n",
      "|     NULL|      020|0183112|           3.24|       3.24|              US|   Credit Card|        false|\n",
      "|     NULL|      020|  01601|          47.17|      47.17|              US|   Credit Card|        false|\n",
      "|     NULL|      020|    020|      848368.75|  848368.75|              US|  Reinvestment|        false|\n",
      "|     NULL|    03566|  03566|       10134.05|   10134.05|              US|  Reinvestment|        false|\n",
      "|     NULL|      011|  02776|       335999.7|   335999.7|              US|        Cheque|        false|\n",
      "|     NULL|      000|    000|         121.98|     121.98|              US|  Reinvestment|        false|\n",
      "|     NULL|      011|0249457|          45.39|      45.39|              US|   Credit Card|        false|\n",
      "|     NULL|      000|    000|           23.4|       23.4|              US|  Reinvestment|        false|\n",
      "|     NULL|    02776|0071901|          30.23|      30.23|              US|   Credit Card|        false|\n",
      "|     NULL|   011081| 011081|           7.37|       7.37|              US|  Reinvestment|        false|\n",
      "+---------+---------+-------+---------------+-----------+----------------+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Timestamp: timestamp (nullable = true)\n",
      " |-- From Bank: string (nullable = true)\n",
      " |-- To Bank: string (nullable = true)\n",
      " |-- Amount Received: float (nullable = true)\n",
      " |-- Amount Paid: float (nullable = true)\n",
      " |-- Payment Currency: string (nullable = true)\n",
      " |-- Payment Format: string (nullable = true)\n",
      " |-- Is Laundering: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что теперь столбцы датафрейма содержат значения корректных типов.\n",
    "\n",
    "Полученный датафрейм сохраним для дальнейшего использования. Сохранение выполним в таблицу `Apache Iceberg`. \n",
    "\n",
    "`Apache Iceberg` — это поддерживающий высокую производительность табличный формат для больших данных.\n",
    "\n",
    "Сначала создадим базу данных, в которой будет расположена таблица. Во избежание путаницы, **каждую таблицу следует называть с использованием фамилии студента**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = \"Khripunov_database\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим инструкцию SQL для добавления базы данных в каталог `Apache Spark`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_database_sql = f\"\"\"\n",
    "CREATE DATABASE IF NOT EXISTS spark_catalog.{database_name}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(create_database_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установим созданную базу данных как текущую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.setCurrentDatabase(database_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И, наконец, записываем преобразованный датафрейм в таблицу `sobd_lab1_table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Сохранение DataFrame в виде таблицы\n",
    "df.writeTo(\"sobd_lab1_table2\").using(\"iceberg\").create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После успешной записи можно посмотреть, какие таблицы входят в базу данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sobd_lab1_table\n",
      "sobd_lab1_table1\n",
      "sobd_lab1_table2\n"
     ]
    }
   ],
   "source": [
    "for table in spark.catalog.listTables():\n",
    "    print(table.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что при необходимости созданные базу данных и таблицу можно удалить следующими командами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"DROP TABLE spark_catalog.Khripunov_database.sobd_lab1_table\")\n",
    "# spark.sql(\"DROP DATABASE spark_catalog.Khripunov_database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После успешной записи таблицы останавливаем сессию `Apache Spark`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
